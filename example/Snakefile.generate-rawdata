N_SAMPLES = 10
LIBS_PER_SAMP = 2
RUNS_PER_LIB = 2
TOTAL_COV = 50
CHROM_LENGTH = 100000
Ne = 1000
RECOMBINATION_RATE = 1e-8
MU = 1e-6
SEED = 1337
READ_ERRRATE = 0.002  # q score of 27
ANCESTRAL = "./lambda/lambda.fasta"


import msprime
import numpy as np
import string
import shutil
import os.path as op


SAMPLES = [f"S{i+1:02d}" for i in range(N_SAMPLES)]
LIBS = {S + l: S for S in SAMPLES for l in string.ascii_lowercase[:LIBS_PER_SAMP]}
RUNS = [f"Run{i+1}" for i in range(RUNS_PER_LIB)]
RUNLIB2SAMP = {(R, L): S for L, S in LIBS.items() for R in RUNS}


def parsefa(filepath):
    seqs = {}
    with open(filepath) as fh:
        seq = []
        seqid = None
        for line in fh:
            if line.startswith(">"):
                if seqid is not None:
                    seqs[seqid] = "".join(x.strip() for x in seq)
                seqid = line[1:].strip().split(" ")[0]
            else:
                seq.append(line)
        if seqid is not None:
            seqs[seqid] = "".join(x.strip() for x in seq)
    return seqs


if ANCESTRAL is not None:
    ANC_GENOME = parsefa(ANCESTRAL)
    if len(ANC_GENOME) != 1:
        raise ValueError("This dumb workflow expects a single contig in the reference genome.")
    ANC_GENOME_SEQID, ANC_GENOME_SEQ = list(ANC_GENOME.items())[0]
    CHROM_LENGTH = len(ANC_GENOME_SEQ)
    print(ANC_GENOME_SEQID, CHROM_LENGTH)

rule all:
    input:
        "rawdata/reference/genome.fa.fai",
        expand("rawdata/genomes/{sample}.fa.fai", sample=SAMPLES),
        expand("rawdata/reads/{run}/{lib}_{R}.fastq.gz", run=RUNS, lib=LIBS, R=["R1", "R2"]),
        "rawdata/rl2s.tsv",
        "rawdata/samples.tsv",
        "rawdata/setfiles/all.txt",


rule faidx:
    input:
        "{path}.fa"
    output:
        "{path}.fa.fai"
    priority: 10
    shell:
        "samtools faidx {input}"


rule metadata:
    output:
        rl2s="rawdata/rl2s.tsv",
        samples="rawdata/samples.tsv",
        setfile="rawdata/setfiles/all.txt",
    run:
        with open(output.rl2s, "w") as file:
            print("run", "library", "sample", "include", sep="\t", file=file)
            for (R, L), S in RUNLIB2SAMP.items():
                print(R, L, S, "Y", sep="\t", file=file)

        with open(output.samples, "w") as file:
            print("sample", "species", "latitude", "longitude", "altitude", "datum", sep="\t", file=file)
            for sample in SAMPLES:
                tue = (48.52, 9.055556, 341)
                lat = np.random.normal(loc=tue[0], scale=0.5, size=1)[0]
                lon = np.random.normal(loc=tue[1], scale=0.5, size=1)[0]
                alt = np.random.normal(loc=tue[2], scale=100, size=1)[0]
                sp = "Pseudoplantus harddrivensis"
                print(sample, sp, lat, lon, alt, "WGS84", sep="\t", file=file)

        with open(output.setfile, "w") as file:
            for sample in SAMPLES:
                print(sample, file=file)


rule genomes:
    output:
        reference="rawdata/reference/genome.fa",
        genomes=expand("rawdata/genomes/{sample}.fa", sample=SAMPLES),
        varpos="rawdata/genomes/variantpos.txt",
    run:
        global ANC_GENOME_SEQ
        global ANC_GENOME_SEQID
        # Simulate coalescent sequences
        tree_sequence = msprime.simulate(
                sample_size=N_SAMPLES,
                Ne=Ne,
                length=CHROM_LENGTH,
                recombination_rate=RECOMBINATION_RATE,
                mutation_rate=MU,
                random_seed=SEED)

        # Fill a random sequence for all sites
        np.random.seed(SEED)
        if ANCESTRAL:
            anc_seq = np.array(list(ANC_GENOME_SEQ)).reshape((1, CHROM_LENGTH))
        else:
            anc_seq = np.random.choice(list("ACGT"), size=CHROM_LENGTH).reshape((1, CHROM_LENGTH))
            ANC_GENOME_SEQ = "".join(anc_seq[0, :])
            ANC_GENOME_SEQID = "AncGenome"
        S = np.repeat(anc_seq, repeats=N_SAMPLES, axis=0)
        varpos = []

        # Per variant site, update allele matrix
        nucs = list("ACGT")
        for variant in tree_sequence.variants():
            np.random.shuffle(nucs)
            pos = int(np.round(variant.site.position))
            varpos.append(pos + 1) # 1-based
            for i, gt in enumerate(variant.genotypes):
                S[i, pos] = nucs[gt]
        for i, sname in enumerate(SAMPLES):
            with open(output.genomes[i], "w") as file:
                print(f">{sname}", file=file)
                print("".join(S[i, :]), file=file)

        with open(output.reference, "w") as file:
            print(f">{ANC_GENOME_SEQID}", file=file)
            print(ANC_GENOME_SEQ, file=file)

        if ANCESTRAL:
            ancgtf = op.splitext(ANCESTRAL)[0] + ".gtf"
            if op.exists(ancgtf):
                shutil.copyfile(ancgtf, "rawdata/reference/genome.gtf")

        with open(output.varpos, "w") as file:
            for p in varpos:
                print(p, file=file)


cov_per_run = int(np.ceil(TOTAL_COV / (RUNS_PER_LIB * LIBS_PER_SAMP)))
reads_per_rl = int(np.ceil(cov_per_run * CHROM_LENGTH / (2 * 100)))
rule reads:
    input:
        lambda wc: expand("rawdata/genomes/{sample}.fa", sample=RUNLIB2SAMP[(wc.run, wc.lib)])
    output:
        r1="rawdata/reads/{run}/{lib}_R1.fastq",
        r2="rawdata/reads/{run}/{lib}_R2.fastq",
    params:
        cov_per_run=cov_per_run,
        reads_per_rl=reads_per_rl,
    shell:
        "wgsim" 
        "   -e 0.005"
        "   -d 500"
        "   -s 100"
        "   -N {params.reads_per_rl}"
        "   -r 0"
        "   -1 100"
        "   -2 100"
        "   {input}"
        "   {output.r1}"
        "   {output.r2}"
        #">/dev/null 2>&1"


rule gzipfq:
    input:
        "{path}.fastq",
    output:
        "{path}.fastq.gz",
    shell:
        "gzip {input}"
