# These rules are part of Acanthophis. See https://github.com/kdm9/Acanthophis.
# This file *could* be modified, but then be careful when you update them. And
# please, if you find a bug, raise an issue on github so the fix gets shared
# with everyone.
#
# Copyright 2016-2024 Kevin Murray/Gekkonid Consulting
#
# This Source Code Form is subject to the terms of the Mozilla Public License,
# v. 2.0. If a copy of the MPL was not distributed with this file, You can
# obtain one at http://mozilla.org/MPL/2.0/.


# TODO: maybe goleft indexcov needs a FOFN?
rule idxcov:
    input:
        bam=lambda wc: T(expand("alignments/samples/{aligner}~{ref}~{sample}.bam",
                                aligner=wc.aligner, ref=wc.ref,
                                sample=config["SAMPLESETS"][wc.sampleset])),
        bai=lambda wc: T(expand("alignments/samples/{aligner}~{ref}~{sample}.bam.bai",
                                aligner=wc.aligner, ref=wc.ref,
                                sample=config["SAMPLESETS"][wc.sampleset])),
    output:
        cov=T("variants/regions/{aligner}~{ref}~{sampleset}~{caller}/cov/cov-indexcov.bed.gz"),
    log:
        L("variants/regions/{aligner}~{ref}~{sampleset}~{caller}/cov/cov-indexcov.log"),
    resources: **rule_resources(config, "idxcov", runtime=60, mem_gb=16, cores=2)
    conda: "envs/idxcov.yml"
    params:
        dir=lambda wc, output: dirname(output.cov)
    shell:
        "goleft indexcov --excludepatt '^$' --directory {params.dir} {input.bam} &>{log}"


checkpoint idxcov_regions:
    input:
        cov=T("variants/regions/{aligner}~{ref}~{sampleset}~{caller}/cov/cov-indexcov.bed.gz"),
    output:
        regionsbed=P("variants/regions/{aligner}~{ref}~{sampleset}~{caller}/regions.bed"),
    params:
        cov_threshold=lambda wc: config["tool_settings"]["varcall"].get("region_coverage_threshold", {}).get(wc.caller, 10000)
    run:
        try:
            import os
            import gzip
            with gzip.open(input.cov, "rt") as fh, \
                    open(output.regionsbed, "w") as bedfh:
                hdr = None
                region_chr = None
                region_start = None
                region_stop = None
                region_total_cov = 0
                for line in fh:
                    if line.startswith("#"):
                        continue
                    fields = line.rstrip("\n").split("\t")
                    chr, start, stop = fields[0:3]
                    start = int(start) + 1
                    stop = int(stop)
                    total_cov = sum(float(x) for x in fields[3:])
                    if chr != region_chr or region_total_cov >= int(params.cov_threshold):
                        # over coverage threshold or chrom changed, new region please
                        if region_chr is not None:
                            region_str = f"{region_chr}:{region_start}-{region_stop}"
                            print(region_chr, region_start - 1, region_stop, region_total_cov, file=bedfh, sep="\t")
                        region_chr = chr
                        region_start = start
                        region_stop = stop
                        region_total_cov = total_cov
                    else:
                        # within threshold, so extend region to encompass this one and add to coverage
                        region_total_cov += total_cov
                        region_stop = stop
                if region_chr is not None:
                    # output last region
                    print(region_chr, region_start - 1, region_stop, region_total_cov, file=bedfh, sep="\t")
        except Exception as exc:
            print(exc)


localrules: bamlist
rule bamlist:
    input:
        bam=lambda wc: T(expand("alignments/samples/{aligner}~{ref}~{sample}.bam",
                            aligner=wc.aligner, ref=wc.ref, sample=config["SAMPLESETS"][wc.sampleset])),
        bai=lambda wc: T(expand("alignments/samples/{aligner}~{ref}~{sample}.bam.bai",
                            aligner=wc.aligner, ref=wc.ref, sample=config["SAMPLESETS"][wc.sampleset])),
    output:
        bamlist=P("variants/raw_split/{aligner}~{ref}~{sampleset}.bamlist"),
        fosn=P("variants/raw_split/{aligner}~{ref}~{sampleset}.fosn"),
    run:
        try:
            with open(output.bamlist, "w") as fh:
                for s in input.bam:
                    print(s, file=fh)
            with open(output.fosn, "w") as fh:
                for s in config["SAMPLESETS"][wildcards.sampleset]:
                    print(s, file=fh)
        except Exception as exc:
            print(exc)

#######################################################################
#                         Varcall one region                          #
#######################################################################
# mpileup or freebayes -> norm -> filter -> premergevariantidx all in one big group

rule mpileup:
    input:
        ref=lambda wc: R(config["data_paths"]["references"][wc.ref]["fasta"], keep_local=True),
        bamlist=P("variants/raw_split/{aligner}~{ref}~{sampleset}.bamlist"),
    output:
        bcf=T("variants/raw_split/mpileup~{aligner}~{ref}~{sampleset}/{region}.bcf"),
    log: L("variants/raw_split/mpileup~{aligner}~{ref}~{sampleset}/{region}.bcf.log"),
    params:
        theta=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("theta_prior", 0.01),
        minmq=lambda wc: config["tool_settings"]["varcall"]["minmapq"].get(wc.aligner, 5),
        max_depth=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("max_depth_per_sample", 200), # Per-sample coverage
        minbq=config["tool_settings"]["varcall"]["minbq"],
        ziplevel=config.get("tool_settings", {}).get('ziplevel', 6),
    resources: **rule_resources(config, "mpileup", runtime=120, mem_gb=4, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    group: "varcall_oneregion"
    shell:
        "( bcftools mpileup"
        "   --redo-BAQ"
        "   --max-depth {params.max_depth}" # per file (i.e. sample) max depth
        "   --min-MQ {params.minmq}"
        "   --min-BQ {params.minbq}"
        "   --fasta-ref {input.ref}"
        "   --annotate FORMAT/DP,FORMAT/AD,FORMAT/SP,INFO/AD" #output extra tags
        "   --region '{wildcards.region}'"
        "   --output-type u" # uncompressed bam
        "   --bam-list {input.bamlist}"
        " | bcftools call"
        "   --threads {threads}"
        "   --targets '{wildcards.region}'" # might not be needed
        "   --multiallelic-caller"
        "   --prior {params.theta}"
        "   -O b{params.ziplevel}" # compressed bcf
        "   -o {output.bcf}"
        " ) >{log} 2>&1"



#######################################################################
#                              Freebayes                              #
#######################################################################
rule freebayes:
    input:
        ref=lambda wc: R(config["data_paths"]["references"][wc.ref]["fasta"], keep_local=True),
        bamlist=P("variants/raw_split/{aligner}~{ref}~{sampleset}.bamlist"),
        fosn=P("variants/raw_split/{aligner}~{ref}~{sampleset}.fosn"),
    output:
        bcf=T("variants/raw_split/freebayes~{aligner}~{ref}~{sampleset}/{region}.bcf"),
    log: L("variants/raw_split/freebayes~{aligner}~{ref}~{sampleset}/{region}.bcf.log"),
    group: "varcall_oneregion"
    params:
        theta=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("theta_prior", 0.01),
        contamination=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("contamination_rate", 0.05),
        ploidy=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("ploidy", 2),
        max_mismatch_frac=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("max_mismatch_frac", 0.10),
        genotype_qualities=lambda wc: "--genotype-qualities" if config["samplesets"][wc.sampleset]["varcall"].get("freebayes_genotype_qualities", False) else "",
        minmq=lambda wc: config["tool_settings"]["varcall"]["minmapq"].get(wc.aligner, 5),
        best_n_alleles=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("best_n_alleles", 4),
        min_alt_count=lambda wc: config["samplesets"][wc.sampleset]["varcall"].get("min_alt_count", 2),
        max_depth=lambda wc: (config["samplesets"][wc.sampleset]["varcall"].get("max_depth_per_sample", 200) *
                              len(config["SAMPLESETS"][wc.sampleset])), # Total coverage, so per samp * n samps
        minbq=config["tool_settings"]["varcall"]["minbq"],
        ziplevel=config.get("tool_settings", {}).get('ziplevel', 6),
    resources: **rule_resources(config, "freebayes", runtime=240, mem_gb=8, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    shell:
        "( freebayes"
        "   --theta {params.theta}"
        "   --ploidy {params.ploidy}"
        "   --use-best-n-alleles {params.best_n_alleles}"
        "   {params.genotype_qualities}"
        "   --min-mapping-quality {params.minmq}"
        "   --min-base-quality {params.minbq}"
        "   --read-max-mismatch-fraction {params.max_mismatch_frac}"
        "   --skip-coverage {params.max_depth}"
        "   --prob-contamination {params.contamination}"
        "   --strict-vcf"
        "   --region '{wildcards.region}'"
        "   --fasta-reference {input.ref}"
        "   --bam-list {input.bamlist}"
        "   --samples {input.fosn}"
        " | bcftools view"
        "   -O b{params.ziplevel}"
        "   -o {output.bcf}"
        " ) >{log} 2>&1"


#######################################################################
#                           Bcftools filter                           #
#######################################################################
rule bcffilter:
    input:
        bcf=T("variants/raw_split/{caller}~{aligner}~{ref}~{sampleset}/{region}.bcf"),
        ref=lambda wc: R(config["data_paths"]["references"][wc.ref]["fasta"], keep_local=True),
    output:
        # Not a pipe! can't run all regions separately if this is a pipe into merge
        bcf=temp(T("variants/filter_split/{caller}~{aligner}~{ref}~{sampleset}~{filter}/{region}.bcf")),
    log:
        L("variants/filter_split/{caller}~{aligner}~{ref}~{sampleset}~{filter}/{region}.bcf.log"),
    params:
        filtarg=lambda wc: config["tool_settings"]["varcall"]["filters"][wc.filter].replace('\n', ' ')
    group: "varcall_oneregion"
    resources: **rule_resources(config, "bcffilter", runtime=120, mem_gb=4, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    shell:
        "( bcftools norm"
        "   --fasta-ref {input.ref}"
        "   --multiallelics -snps"  # Split multi-alleics to filter each allele separately
        "   -O u"
        "   {input.bcf}"
        " |  bcftools view"
        "   {params.filtarg}"
        "   -O u"
        "   /dev/stdin"
        " | bcftools norm" # We normalise here to re-join multi-allelic sites, after filtering with multi-allelics split
        "   --fasta-ref {input.ref}"
        "   --do-not-normalize"
        "   --multiallelics +snps" # re-join multi-alleic sites
        "   -O u"
        "   -o {output.bcf}"
        " ) >{log} 2>&1"


rule premergevariantidx:
    input:
        T("variants/{stage}_split/{path}")
    output:
        temp(T("variants/{stage}_split/{path}.csi"))
    log:
        T("variants/{stage}_split/{path}.csi.log")
    resources: **rule_resources(config, "variantidx", runtime=720, mem_gb=8, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    group: "varcall_oneregion"
    shell:
        "bcftools index -f {input}"


#######################################################################
#                              Bcf Merge                              #
#######################################################################
def batched(iterable, n):
    """Batch data into lists of length n. The last batch may be shorter.
    
    From the itertools docs
    """
    from itertools import islice
    # batched('ABCDEFG', 3) --> ABC DEF G
    if n < 1:
        raise ValueError('n must be at least one')
    it = iter(iterable)
    while (batch := list(islice(it, n))):
        yield batch


def get_regions(wc, chunked=False):
    """Scan the region directory from the checkpoint, and work out what regions we have"""
    regbed = config["data_paths"]["references"][wc.ref].get("region_beds", {}).get(wc.caller)
    if regbed is None:
        regbed = checkpoints.idxcov_regions.get(aligner=wc.aligner, ref=wc.ref, sampleset=wc.sampleset, caller=wc.caller).output.regionsbed
    regions = []
    with open(regbed) as fh:
        for line in fh:
            region_chr, region_start, region_stop, = line.rstrip("\n").split("\t")[:3]
            region_start = int(region_start) + 1
            regions.append(f"{region_chr}:{region_start}-{region_stop}")
    if chunked:
        return {f"group{i}": list(group) for i, group in enumerate(batched(regions, 100))}
    return regions


rule bcfmerge2group:
    input:
        bcf=lambda wc: expand(T("variants/{stage}_split/{caller}~{aligner}~{ref}~{sampleset}{filter}/{region}.bcf"),
                    caller=wc.caller, aligner=wc.aligner, ref=wc.ref, sampleset=wc.sampleset,
                    filter=(f"~{wc.filter}" if wc.filter != "raw" else ""),
                    stage=("filter" if wc.filter != "raw" else "raw"),
                    region=get_regions(wc, chunked=True)[wc.group]),
        bcfi=lambda wc: expand(T("variants/{stage}_split/{caller}~{aligner}~{ref}~{sampleset}{filter}/{region}.bcf.csi"),
                    caller=wc.caller, aligner=wc.aligner, ref=wc.ref, sampleset=wc.sampleset,
                    filter=(f"~{wc.filter}" if wc.filter != "raw" else ""),
                    stage=("filter" if wc.filter != "raw" else "raw"),
                    region=get_regions(wc, chunked=True)[wc.group]),
        regbed=lambda wc: config["samplesets"][wc.sampleset].get("varcall", {}).get("region_beds", {}).get(wc.ref, {}).get(wc.caller, [])
    output:
        bcf=T("variants/group_merged/{caller}~{aligner}~{ref}~{sampleset}~{filter}~{group}.bcf"),
        bcfi=T("variants/group_merged/{caller}~{aligner}~{ref}~{sampleset}~{filter}~{group}.bcf.csi"),
    log:
        T("variants/group_merged/{caller}~{aligner}~{ref}~{sampleset}~{filter}~{group}.bcf.log"),
    resources: **rule_resources(config, "bcfmerge2group", runtime=1440, mem_gb=12, cores=4)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    params:
    shell:
        "( bcftools concat"
        "   --threads {threads}"
        "   --allow-overlaps"
        "   --rm-dups all"
        "   -o {output.bcf}"
        "   {input.bcf}"
        " && bcftools index "
        "   {output.bcf}"
        " ) >{log} 2>&1"


rule bcfmerge:
    input:
        bcf=lambda wc: expand(T("variants/group_merged/{caller}~{aligner}~{ref}~{sampleset}~{filter}~{group}.bcf"),
                    caller=wc.caller, aligner=wc.aligner, ref=wc.ref, sampleset=wc.sampleset, filter=wc.filter,
                    group=get_regions(wc, chunked=True)),
        regbed=lambda wc: config["samplesets"][wc.sampleset].get("varcall", {}).get("region_beds", {}).get(wc.ref, {}).get(wc.caller, [])
    output:
        vcf=P("variants/final/{caller}~{aligner}~{ref}~{sampleset}~{filter}.vcf.gz"),
    log:
        L("variants/final/{caller}~{aligner}~{ref}~{sampleset}~{filter}.vcf.gz.log"),
    resources: **rule_resources(config, "bcfmerge", runtime=1440, mem_gb=12, cores=64)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    params:
        ziplevel=config.get("tool_settings", {}).get('ziplevel', 6),
    shell:
        "( bcftools concat"
        "   --threads {threads}"
        "   --allow-overlaps"
        "   -o {output.vcf}"
        "   -O z{params.ziplevel}"
        "   {input.bcf}"
        " ) >{log} 2>&1"


#######################################################################
#                              BCF stats                              #
#######################################################################
rule vcfstats:
    input:
        P("variants/{path}.vcf.gz")
    output:
        P("variants/{path}.vcf.gz.stats")
    log: L("variants/{path}.vcf.gz.stats.log")
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    resources: **rule_resources(config, "vcfstats", runtime=720, mem_gb=4, cores=4)
    shell:
        "bcftools stats -s - -d 0,1000,1 --threads {threads} {input} >{output}"


#######################################################################
#                       Misc variant processing                       #
#######################################################################
rule vcf2bcf:
    input:
        vcf=P("variants/final/{path}.vcf.gz"),
    output:
        bcf=P("variants/final/{path}.bcf"),
    log: L("{path}.vcf.gz.log"),
    resources: **rule_resources(config, "vcf2bcf", runtime=720, mem_gb=8, cores=8)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    params:
        ziplevel=config.get("tool_settings", {}).get('ziplevel', 6),
    shell:
        "( bcftools view"
        "   {input.vcf}"
        "   -O b{params.ziplevel}"
        "   --threads {threads}"
        "   -o {output.bcf}"
        " ) >{log} 2>&1"


rule finalvarianttbi:
    input:
        P("variants/final/{path}.vcf.gz")
    output:
        P("variants/final/{path}.vcf.gz.tbi"),
    resources: **rule_resources(config, "finalvarianttbi", runtime=720, mem_gb=8, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    shell:
        "bcftools index -t -f {input}"


rule finalvariantidx:
    input:
        P("variants/final/{path}")
    output:
        P("variants/final/{path}.csi")
    resources: **rule_resources(config, "finalvariantidx", runtime=720, mem_gb=8, cores=1)
    conda: "envs/varcall.yml"
    container: "docker://ghcr.io/kdm9/varcall:latest"
    shell:
        "bcftools index -f {input}"


#######################################################################
#                             Target Rules                            #
#######################################################################
rule all_filtered_variants:
    input:
        [P(expand("variants/final/{caller}~{aligner}~{ref}~{sampleset}~{filter}.{ext}",
               ext=["bcf", "bcf.csi", "vcf.gz", "vcf.gz.csi", "vcf.gz.stats"] if config["tool_settings"].get("varcall", {}).get("make_bcfs", False)
                else ["vcf.gz", "vcf.gz.csi", "vcf.gz.stats"],
               caller=filter(lambda x: x in ["mpileup", "freebayes"], config["samplesets"][sampleset]["varcall"]["callers"]),
               aligner=config["samplesets"][sampleset]["varcall"]["aligners"],
               ref=config["samplesets"][sampleset]["varcall"]["refs"],
               filter=config["samplesets"][sampleset]["varcall"]["filters"],
               sampleset=sampleset))
         for sampleset in config["samplesets"]
         if "varcall" in config["samplesets"][sampleset]
         ],


rule all_varcall:
    input:
        rules.all_filtered_variants.input,
        rules.all_deepvariant.input,
